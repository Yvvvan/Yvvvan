---
layout:     post
title:      "机器人学中的状态估计-03"
subtitle:   "K3 - LG系统下Recursive Filter"
date:       2020-11-20
author:     "Yvan"
header-img: "img/in-post/ser0/rse-3.jpg"
header-mask: 0.3
no-catalog: false
mathjax: true
category: "auto"
tags:
    - 状态估计
    - 控制学
typora-root-url: ..
typora-copy-images-to: ..\img\in-post\ser
---

# Estimation Machinery

# K3 Linear-Gaussian Estimation - 2

## 上回小结

K3主要分析 `线性高斯系统(LG)`

首先将LG系统抽象为`运动方程`和`观测方程`

So <img src="/img/in-post/ser/k3model2.png" alt="k3model2" style="zoom: 67%;" />

目的是求解: 系统状态 x, 即 $\hat{x}$ **后验的协方差和均值**。



首先从两种角度入手 分别是 最大后验概率估计`MAP` 和 贝叶斯推断`Bayesian inference`

> 这两种方法结果一样是因为 $\hat{x}$服从正态分布，均值处就是最大概率处。

都得到了方程：

<center> <font size=3>$(H^{T}W^{-1}H) \hat{x}=H^{T}W^{-1}z$</font><br/><br/>
$ z = \left[ \begin{matrix} v \\ y  \end{matrix}\right] \qquad H = \left[ \begin{matrix} A^{-1} \\ C  \end{matrix}\right]  \qquad W = \left[ \begin{matrix} Q & \\  & R  \end{matrix}\right]    $ </center>

解方程组首先使用了 `cholesky smoother` 最后得到了5个前向公式和1个后向公式

<img src="/img/in-post/ser/k3hwh4.png" alt="k3hwh4" style="zoom:90%;" />

基于`cholesky smoother`  使用`卡尔曼增益`，可以将这6个方程改写成 `RTS smoother` **先验协方差，先验均值，卡尔曼增益，前向后验协方差更新，前向后验均值更新，前向后验均值修正** 的形式

<img src="/img/in-post/ser/k3rts15.png" alt="image-20201120223254186" style="zoom: 55%;" />

## 这回内容

上一页主要解决上述三四层关系的详细推导，

这一页

1 关于方程 $(H^{T}W^{-1}H) \hat{x}=H^{T}W^{-1}z$ **何时有解**。

2 **卡尔曼滤波器**的内容。



---

### 3.1.4 Existence, Uniqueness, and Observability

$\hat{\mathbf{x}}=\left(\mathbf{H}^{T} \mathbf{W}^{-1} \mathbf{H}\right)^{-1} \mathbf{H}^{T} \mathbf{W}^{-1} \mathbf{z}$<br/>so it has a  unique solution if and only if $(H^{T}W^{-1}H) $ is invertible.<br/>and $\mathbf{x}$ is in shape (N(K+1),1) / $\operatorname{dim}{\mathbf{x}} = N(K+1)$     ($x_i \in R^N, \mathbf{x} = [x_0, x_1 ... x_k]^T$), so <br/>$\operatorname{rank}\left(\mathbf{H}^{T} \mathbf{W}^{-1} \mathbf{H}\right)=N(K+1)$<br/>and $\mathbf{W^{-1}}$ is invertible and positive definite. so we can drop it. That means<br/><center>$\hat{\mathbf{x}}$ is a unique solution $\rightleftharpoons \operatorname{rank}\left(\mathbf{H}^{T}\right)=N(K+1)$</center>

In other words, we need N(K+1) linearly independent rows (or columns) in the matrix $\mathbf{H}^{T}$ .

We now have two cases that should be considered:<br/>
(i) We have good prior knowledge of the initial state, $\check{x}_0$.<br/>
(ii) We do not have good prior knowledge of the initial state.<br/>

#### case (i) with initial state

write out $\mathbf{H^T} $ just like in 3.2.2.5. we will find out the matrix is in block-row-echelon from, which means full rank.

<img src="/img/in-post/ser/k3rank1" alt="image-20201121001618163" style="zoom: 80%;" />

$\operatorname{rank}\mathbf{H^T} = N(K+1)$

and the solution is unique.

#### case (ii) without initial state

this means remove the **first column** in $\mathbf{H^T} $

<img src="/img/in-post/ser/k3rank2" alt="image-20201121001655073" style="zoom:80%;" />

moving the top row to the bottom:<br/><img src="/img/in-post/ser/k3rank4" alt="image-20201121001837632" style="zoom:80%;" />

let the $\mathbf{A} $ part of the last row become $\mathbf{0} $ by adding $\mathbf{A_0^T} $  times first row to it, and then $\mathbf{A_0^T}\mathbf{A_1^T} $  times first row  .... <br/><img src="/img/in-post/ser/k3rank3" alt="image-20201121002332914" style="zoom:80%;" />

the upper block is full rank of $NK$

so if the bottom block is full rank of $N$, the solution is unique.

<img src="/img/in-post/ser/k3rank5" alt="image-20201121003738590" style="zoom:80%;" />

即 可观 = 有唯一解

### 3.3 Recursive Discrete-Time Filtering

0. 递归最小二乘法RLS <*RLS*和*卡尔曼滤波器*非常类似> (会用在4中运用)
1. RTS的前向部分 即为卡尔曼滤波器 **最好先把上一次的RTS看懂**
   1. 经典形式 卡尔曼增益是修正的权重
   2. 信息形式 信息矩阵是协方差矩阵的逆，即不用卡尔曼增益的形式
2. 从MAP出发推导 （即 H W z 简化为 关于 k-1 和 k 时刻 的矩阵， 而非 从0到k时刻的矩阵）
3. 从贝叶斯推断出发推导 （不通过HWHx=HWz, 直接从概率出发推导）
4. 从gain optimization推导

#### 0. RLS

<img src="/img/in-post/ser/image-20201203114535970.png" alt="image-20201203114535970" style="zoom: 67%;" />

> 求J的最小值，就是二次函数最小值，J导=0 得到 xi

<img src="/img/in-post/ser/image-20201203121118383.png" alt="image-20201203121118383" style="zoom:67%;" />

> 令P的逆等于x中第一项，把其中Ai写成[Ai-1，Fi]的形式，得到Pi的逆递归式。
>
> 用SMW恒等式整理（Pi的逆递归式的逆），得到Pi的递归式。

<img src="/img/in-post/ser/image-20201203121405794.png" alt="image-20201203121405794" style="zoom:67%;" />

> 用 Γ， K替换 得到 第4式 Pi
>
> 再推导以下Ki和Pi的关系 见下方
>
> 第3个式子 xi的推导见下下方

<img src="/img/in-post/ser/image-20201203124010890.png" alt="image-20201203121405794" style="zoom: 60%;" />

<img src="/img/in-post/ser/image-20201203122249179.png" alt="image-20201203121405794" style="zoom:67%;" />

> xi 是 最开始得到的结论（1.2）
>
> 用之前假设的Pi去替换
>
> 把 Ai bi 都拆开，为了递归，并且乘出来
>
> Pi的递归式代入
>
> 发现了Pi-1Ai-1bi-1就是1.2中的xi-1 （递归起来了）
>
> 代入Ki-Pi的结论 整理
>
> 得到递归式



#### 2. MAP

> 考虑k-1时刻和k时刻的关系

<img src="/img/in-post/ser/image-20201203152937466.png" alt="image-20201203152937466" style="zoom: 67%;" />

<img src="/img/in-post/ser/image-20201203155229388.png" alt="image-20201203155229388" style="zoom: 67%;" />

<img src="/img/in-post/ser/image-20201203153043013.png" alt="image-20201203153043013" style="zoom: 67%;" />

1. 代入

   ​	<img src="/img/in-post/ser/image-20201203155448446.png" alt="image-20201203155448446" style="zoom: 67%;" />

2. 消去 后验x'k-1

   > 用舒尔补进行消去：
   >
   > ​	可以直接从Ax+By=a,Cx+Dy=b入手 写出 Ky=d
   >
   > ​	也可以用求舒尔补的矩阵打洞过程把2,1位置变成0 得到 Ky=d

   <img src="/img/in-post/ser/image-20201203182541858.png" alt="image-20201203182541858" style="zoom: 33%;" />

3. 后验xk

   > 使用的是SMW第一式
   
   <img src="/img/in-post/ser/image-20201203182613348.png" alt="image-20201203182613348" style="zoom: 33%;" />

4. 定义 先验xk，先验Pk，后验Pk

   <img src="/img/in-post/ser/image-20201203190054135.png" alt="image-20201203190054135" style="zoom: 50%;" />

5. 代入得到

   <img src="/img/in-post/ser/image-20201203190209140.png" alt="image-20201203190209140" style="zoom:50%;" />

   > 即`信息形式`的RTS前向部分
   
6. 加入卡尔曼增益 K

   > 具体方法可以看上一次的RTS部分。这边有很多代入方法。

   <img src="/img/in-post/ser/image-20201203192049522.png" alt="image-20201203192049522" style="zoom: 67%;" />

   > 得到 `经典形式` 的卡尔曼滤波器
   >
   > 
   >
   > 意义： 
   >
   > 1. k-1时刻的后验  -- system dynamics ->    k时刻的先验：
   >
   >    是根据 输入 和 k-1时刻的**估计**状态 做出的**猜测**
   >
   >    输入 input **v**
   >
   >    输入噪音 process noise w ~ N(0,**Q**)
   >
   > 2. k时刻的先验 -- measurment model ->    k时刻的后验:
   >
   >    是根据 **测量** 和 k时刻的猜测 做出的最后修正**估计**结果
   >
   >    测量 mesurment **y**
   >
   >    测量噪音 mesurment noise n~ N(0,**R**)
   >
   >    y-Cx 是实际测量和理论测量的差 = 一个修正
   >
   > 
   >
   > 卡尔曼增益 kalman gain : 
   >
   > how much you want to take the prediction in account. if **R** is very large,  so the measurement is very uncertain, so we get a smaller K. that means we don't trust the measurement. 
   >
   > 
   >
   > 协方差：与输入和测量无关，所以每次都只需要求均值即可。



#### 3. Bayesian Law

> 先算Prior
>
> 先验均值，和上一回的时候一样的做法，简化一下。
>
> 先验协方差，和上回测量协方差的步骤差不多。
>
> > 下图 
> >
> > k-1时刻: 在 一串到k-1时刻的输入和测量 条件下的 计算 就是**估计** 是 后验k-1
> >
> > k时刻: 比上一个k-1多了一个k时刻的输入 这时的计算 是**猜测** 是先验k
> >
> > k的先验和MAP中一样

<img src="/img/in-post/ser/image-20201203215659116.png" alt="image-20201203215659116" style="zoom: 67%;" />

<img src="/img/in-post/ser/image-20201203214421376.png" alt="image-20201203214421376" style="zoom: 67%;" />

> 然后算Joint Probability 和上一次一样
>
> 接着是用高斯推断算Posterior 和上次一样

<img src="/img/in-post/ser/image-20201203220820716.png" alt="image-20201203220820716" style="zoom: 55%;" />

<img src="/img/in-post/ser/image-20201203221047919.png" alt="image-20201203221047919" style="zoom: 55%;" />

#### 4. Gain Optimization

> 假设 后验(修正过的估计) 是 先验(猜测) + 修正(测量修正) * 修正的比例(K)
>
> 也就是我们先假设了 后验xk = 先验xk + Kk(yk-Ck*先验xk) 这个式子
>
> 然后我么找最合适的K

<img src="/img/in-post/ser/image-20201203223726946.png" alt="image-20201203223726946" style="zoom:50%;" />

> 用cost function
>
> 先定义偏差时 后验x(修正过的估计) - 实际

<img src="/img/in-post/ser/image-20201203223621725.png" alt="image-20201203223621725" style="zoom:50%;" />

<img src="/img/in-post/ser/image-20201203223550838.png" alt="image-20201203223550838" style="zoom:50%;" />

#### 卡尔曼滤波器

<img src="/img/in-post/ser/image-20201203224833279.png" alt="image-20201203224833279" style="zoom:67%;" />

#### 最优线性无偏估计(BLUE)

<img src="/img/in-post/ser/image-20201203230620866.png" alt="image-20201203230620866" style="zoom:67%;" />

<img src="/img/in-post/ser/image-20201203230639819.png" alt="image-20201203230639819" style="zoom:67%;" />

<img src="/img/in-post/ser/image-20201203230705605.png" alt="image-20201203230705605" style="zoom: 67%;" />





## 总结

Smoother

- Batch Discrete-Time Estimation (得到方程，用线性代数的方法解方程)
  - MAP
  - 贝叶斯

- Recursive Discrete-Time Smoothing (用recursive的方法求解方程)
  - Cholesky 
  - RTS

Filter

- Recursive Discrete-Time Filtering
  - KF

<img src="/img/in-post/ser/image-20201231134014102.png" alt="image-20201231134014102" style="zoom: 67%;" />

<img src="/img/in-post/ser/image-20201231134052254.png" alt="image-20201231134052254" style="zoom:67%;" />

---



## SER目录

| SER目录                                    |                                 |      |
| ------------------------------------------ | ------------------------------- | ---- |
| [SER-1](../../../../../../2020/10/26/SER)  | K2 - 基础概率论                 |      |
| [SER-2](../../../../../../2020/11/09/SER2) | K3 - LG系统下Batch/Smoother     |      |
| [SER-3](../../../../../../2020/11/20/SER3) | K3 - LG系统下Recursive Filter   |      |
| [SER-4](../../../../../../2020/12/04/SER4) | K4 - NLNG系统下Recursive Filter |      |
| [SER-5](../../../../../../2020/12/31/SER5) | K4 - NLNG系统下Batch            |      |
| [SER-6](../../../../../../2021/01/15/SER6) | K5 - 偏差,匹配和外点            |      |