---
layout:     post
title:      "机器人学中的状态估计-02"
subtitle:   "LG系统"
date:       2020-11-09
author:     "Yvan"
header-img: "img/in-post/rse-2.jpg"
header-mask: 0.3
no-catalog: false
mathjax: true
tags:
    - SER
typora-root-url: ..
---

# Estimation Machinery

> 分成了 `线性高斯系统(LG)`  和  `非线性非高斯(NLNG)` 系统 分别在K3 K4分析。
>
> 这一页主要涉及LG系统下，通过[MAP](#312-maximum-a-posteriori-map)和[贝叶斯推断](#313-bayesian-inference)，以及[Cholesky smoother](#322-cholesky-smoother)和[RTS smoother](#323-rauch-tung-striebel-rts-smoother) 详细求解`运动方程`及`观测方程`的过程。

## K3 Linear-Gaussian Estimation - 1

### 3.1 Batch Discrete-Time Estimation

#### 3.1.1 Setup

for **linear, time-varying models**: we need

a **motion model** and a **observation model**:

<img src="/img/in-post/ser/k3model1.png" style="zoom:80%;" />

> 关于正负号好像略微有点问题，但不影响理解。

So <img src="/img/in-post/ser/k3model2.png" alt="k3model2" style="zoom: 75%;" />



> 分成 `batch linear-Gussain techniques (smoothers)`和 `recursive state estimators (filters)` 分别在3.1.2 MAP + 3.1.3 Bayesian 和  3.3 Kalman Filter

即求解: $\hat{x}$  (posterior) **后验的协方差和均值**.

---

#### 3.1.3 Bayesian inference

Base on the **Bayesian Rule** with joint & condition: 

<img src="/img/in-post/ser/k3bayes1 - 副本.png" alt="k3bayes1 - 副本" style="zoom: 67%;" />

we calculate the `prior` and the `observation` to get the `joint`.

change x and y: 

<img src="/img/in-post/ser/k3bayes2 - 副本.png" alt="k3bayes2 - 副本" style="zoom:67%;" />

now based on the **Gaussian Inference** we can use `joint` to infer `posterior`

1. **For the Prior:**

   <img src="/img/in-post/ser/k3bayes3.png" alt="k3bayes3" style="zoom: 60%;" />

2. **For the Observation:**

   <img src="/img/in-post/ser/k3bayes4.png" alt="k3bayes4" style="zoom:50%;" />

3. **For the Joint:**

   <img src="/img/in-post/ser/k3bayes5.png" alt="k3bayes5" style="zoom: 50%;" />

4. **For the Posterior:**

   <img src="/img/in-post/ser/k3bayes6.png" alt="k3bayes6" style="zoom: 46%;" />

---

#### 3.1.2 Maximum A Posteriori (MAP)

in batch estimation is to solve:

<img src="/img/in-post/ser/k3map1.png" alt="k3map1" style="zoom: 80%;" />

with Bayes' rule: \<same as in 3.1.3\>

<img src="/img/in-post/ser/k3map2.png" alt="k3map2" style="zoom: 67%;" />

by assuming noise variables are uncorrelated:

<img src="/img/in-post/ser/k3map3.png" alt="k3map3" style="zoom: 67%;" />

<img src="/img/in-post/ser/k3map4.png" alt="k3map4" style="zoom:67%;" />

using log function to convert × into +:

<img src="/img/in-post/ser/k3map5.png" alt="k3map5" style="zoom:67%;" />

the component parts are:

<img src="/img/in-post/ser/k3map6.png" alt="k3map6" style="zoom: 50%;" />

here for example:

<img src="/img/in-post/ser/k3map7.png" alt="k3map7" style="zoom:50%;" />

give them into a log function:

<img src="/img/in-post/ser/k3map8.png" alt="k3map8" style="zoom:67%;" />

merge them together to get a **cost function** J(x):

<img src="/img/in-post/ser/k3map9.png" alt="k3map9" style="zoom:67%;" />

the same as 3.1.3.(4), rewrite the cost function in matrix way:

<img src="/img/in-post/ser/k3map10.png" alt="k3map10" style="zoom:67%;" />

now we calculat the x which reaches the minimum of J:<br/>we found that J(x) is a quadratic function:

> ![k3map11](/img/in-post/ser/k3map11.png)
>
> 对于一维二次函数 找最小值就是 一阶导数等于0，二阶导数大于0。
>
> 对于高维二次函数 同理：
>
> 先对 **f(x+Δx)进行高维泰勒展开**如图:
>
> > <img src="/img/in-post/ser/k3taylor.png" alt="k3taylor" style="zoom: 80%;" />
>
> 再对**x+Δx 代入 f(x)**进行展开
>
> 比较系数可得泰勒展开中，Δx前的系数即为x的偏导数。
>
> 那么如果 f(x)是：
>
> <img src="/img/in-post/ser/k3map12.png" alt="k3map12" style="zoom: 48%;" />

so 

<img src="/img/in-post/ser/k3map13.png" alt="k3map13" style="zoom: 67%;" />

we get the exact equation as in 3.1.3.(4)

<center> <font size=5>$(H^{T}W^{-1}H) \hat{x}=H^{T}W^{-1}z$</font></center>

---

---

**Now what?**

### 3.2 Recursive Discrete-Time Smoothing

#### 3.2.2 Cholesky Smoother

**to solve the equation:**

1. **$A$ and $A^{-1}$**

   <img src="/img/in-post/ser/k3calculate.png" alt="k3calculate" style="zoom: 50%;" />

   > 1 下三角矩阵求逆
   >
   > 2 **Markov property**

2. **$H^TW^{-1}h$**

   <img src="/img/in-post/ser/k3calculate2.png" alt="k3calculate2" style="zoom: 50%;" />

3. using  **[cholesky decomposition](https://yvvvan.github.io/2020/10/30/matrix/#cholesky-%E5%88%86%E8%A7%A3)** : **$H^TW^{-1}h = LL^T$** with

   <img src="/img/in-post/ser/k3calculate3.png" alt="k3calculate3" style="zoom:50%;" />

4. reform

   $(H^{T}W^{-1}H) \hat{x}=H^{T}W^{-1}z$

   $LL^T\hat{x}=H^{T}W^{-1}z$

   **$Ld=H^{T}W^{-1}z$**  with **$L^T\hat{x}=d$**

5. solve

   **solve $Ld=H^{T}W^{-1}z$ for $d$ forward**

   **solve $L^T\hat{x}=d$ for $x$ backward**

> $H = \left[ \begin{matrix} A^{-1} \\\\\\ C  \end{matrix}\right] \qquad A \& A^{-1} (step 1) \qquad C = diag(...)$ 
>
> $H^T = \left[ \begin{matrix} A^{-T}  C^T  \end{matrix}\right]$ 
>
> <br/>
>
> $W = \left[ \begin{matrix} Q & \\\\\\  & R  \end{matrix}\right]  \qquad Q = diag(...) \qquad R= diag(...) $
>
> $W = diag(w_0,w_1,...)$
>
> $W^{-1} = diag(w_0^{-1},w_1^{-1},...)$
>
> <br/>
>
> $H^TW^{-1}H$展开乘出来
>
> <img src="/img/in-post/ser/k3hwh1.png" alt="k3hwh1" style="zoom: 33%;" />
>
> <img src="/img/in-post/ser/k3hwh2.png" alt="k3hwh2" style="zoom: 33%;" />
>
> <img src="/img/in-post/ser/k3hwh3.png" alt="k3hwh3" style="zoom: 33%;" />
>
> 总结：
>
> 1. 解HWH=LL 得到L
> 2. 解Ld=HWz 得到d
> 3. 解Lx=d 得到x

<img src="/img/in-post/ser/k3hwh4.png" alt="k3hwh4"  />

> 等价于RTS-smoother, 其中前五个前向迭代等价于卡尔曼滤波器

---

#### 3.2.3 Rauch-Tung-Striebel (RTS) smoother 

> 上课一页PPT飞过

整个RTS由5+1个式子+3个初始状态构成：(1-5由前向得到，6由后向得到)<br/>

 **前向**：<br/>1. 先验协方差方程 A.3.1<br/>2. 先验均值方程 B.5.1<br/>3. 卡尔曼增益 A.4<br/>4. 后验协方差更新方程 A.5<br/>5. 后验均值更新方程 B.6

**后向**：<br/>1. 前向后验修正方程 C.3 

<p style = "margin:5px"><b>初始状态</b>： </p>
<p style = "margin:5px">1. $\check{P}_{0,f} = \check{P}_0$ </p>
<p style = "margin:5px">2. $\check{x}_{0,f} = \check{x}_0$</p>
<p style = "margin:5px">3. $\hat{x}_K = \hat{x}_K{}_f$</p>

<img src="/img/in-post/ser/k3rts15.png" alt="k3rts15" style="zoom: 63%;" />

---

先观察**5个前向迭代**的式子 3.66a-3.66e:

**A. 后验协方差部分**

1. 由**c式**解出 $L_{k,k-1}$，代入**d式**，化简过程中出现**a式**再代入：

   <img src="/img/in-post/ser/k3rts1.png" alt="k3rts1" style="zoom: 50%;" />

2. 使用**SMW**化简，得到 $I_k$的递推表达式：

   <img src="/img/in-post/ser/k3rts2.png" alt="k3rts2" style="zoom: 50%;" />

   > $I$即 `信息矩阵` information matrix。信息矩阵是协方差的逆。

3. 令 $\hat{P}_{k,f} = I_k^{-1}$ (其中 $f$代表forward)，则：(这么设是因为信息矩阵的逆是协方差矩阵)

   <img src="/img/in-post/ser/k3rts3.png" alt="k3rts3" style="zoom: 80%;" />

   > 第一个式子代表 `先验`/**预测**的协方差
   >
   > 第二个式子代表`后验`/**修正**的协方差 (4-5进一步用卡尔曼增益变形该式)
   >
   > 即代表：
   >
   > 用**k-1的后验**预测得到**k的先验**，在通过**k的先验**修正成**k的后验**。（这个过程就是卡尔曼滤波过程）

4. 令 $K_k = \hat{P}_{k,f}C_k^TR_k^{-1}$，并将第二式代入K消去**后验**, 并使用**SMW**变换：(这么设是因为要写成经典形式，K是卡尔曼增益)

   <img src="/img/in-post/ser/k3rts4.png" alt="k3rts4" style="zoom: 80%;" />

   即可通过**先验**求得K

5. 那么根据第二式：

   <img src="/img/in-post/ser/k3rts5.png" alt="k3rts5" style="zoom:50%;" />

   <img src="/img/in-post/ser/k3rts5.1.png" alt="k3rts5.1" style="zoom: 80%;" />

   > **协方差更新方程**：即**后验**协方差对**先验**协方差的更新/修正

**B. 均值部分**

1. 由**b式**解出 $d_{k-1}$，由**c式**解出 $L_{k,k-1}$，相乘得到 $L_{k,k-1}d_{k-1}$：

   <img src="/img/in-post/ser/k3rts6.png" alt="k3rts6" style="zoom: 55%;" />

2. 将**a式**代入上述式子，并将所得式子代入**e式**，并通过两次**SMW**变换：

   <img src="/img/in-post/ser/k3rts7.png" alt="k3rts7" style="zoom:50%;" />

3. 用 **协方差部分 3**的设，即协方差是信息矩阵的逆，以及协方差两个公式，替代上式信息矩阵部分：

4. 且令 <img src="/img/in-post/ser/k3rts8.png" alt="k3rts8" style="zoom: 50%;" />

   则：

   <img src="/img/in-post/ser/k3rts8.jpg" alt="k3rts8" style="zoom: 80%;" />

5. 整理得到：

   <img src="/img/in-post/ser/k3rts9.png" alt="k3rts9" style="zoom: 80%;" />

   > 类似于**协方差部分** 得到了两个式子：
   >
   > 1. k的先验均值 由k-1的后验均值预测得出
   > 2. k的后验均值 由k的先验均值修正得出 (6进一步用卡尔曼增益变形该式)

6. 用卡尔曼增益进一步整理，左右两边同时乘协方差矩阵，右边第一部分根据**协方差部分**的结论写成(1-KC)，第二部分根据K的定义写成K：

   <img src="/img/in-post/ser/k3rts10.png" alt="k3rts10" style="zoom: 50%;" />

   <img src="/img/in-post/ser/k3rts11.png" alt="k3rts11" style="zoom:80%;" />

   > **均值更新方程**

---

观察**后向迭代式**3.66f:

**C. 后向迭代**

1. 左右同乘 $L_{k-1}$:

   <img src="/img/in-post/ser/k3rts12.png" alt="image-20201120172916046" style="zoom: 50%;" />

2. 代入**a,b,c式**，然后用**SMW**：

   > 乘进去很快能看出来怎么代入

   <img src="/img/in-post/ser/k3rts13.png" alt="image-20201120175339012" style="zoom: 50%;" />

3. 利用之前的公式(A.3, B.4, B.5)代入消去I和q：

   > 写一下很容易代入整理完成

   <img src="/img/in-post/ser/k3rts14.png" alt="image-20201120214056337" style="zoom:80%;" />

   > k-1的后验 是 前向后验 + 修正

---

---

<img src="/img/in-post/ser/k3solution.png" alt="k3solution" style="zoom: 67%;" />